\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{biblatex}
\addbibresource{bibliography.bib}

\title{Variations on Normalisation by Evaluation for the Lambda Calculus }
\author{Lucas O'Dowd-Jones}
\date{}

\begin{document}

\maketitle

\section{Introduction}
\subsection{What is NbE?}
Indentify common features - eval and reify, interpret by semantic set in "host" language

Difference to reduction-based

\subsection{Motivation for NbE}

More efficient?

Avoids infinite reduction (terms not strongly normalisable - eg K x omega)

\subsection{Why NbE in Haskell?}

Modern technqiues for elegant implementation (GADTs)

\section{NbE for the Untyped Lambda Calculus}
\subsection{Syntax}
\begin{align}
    N_f &:= N_e \mid \lambda.N_f  \\
    N_e &:= N_e N_f \mid n
\end{align}
\cite{slides}

\subsection{Semantics}
Interpreted by the set V \cite{slides}
$$
    V := N_e \mid V \rightarrow V
$$

Problem: fresh variables

\subsection{Fresh variables solution 1 - Gensym}
approach based on \cite{slides}

Implemented with State monad

Issue with solution 1: Have to add monad everywhere (inescapable) - all functions dependent on state

"Less functional" - carry around state (may as well use imperative)

\subsection{Fresh variables solution 2 - Locally nameless terms}
approach based on \cite{deBruijn}

Uses de Bruijn Indicies for syntax and deBruijn levels for semantics

index n references nth abstraction,
if m abstractions: if n < m bound variables, otherwise free variable

Shifting for abstractions

\section{Implementing the Typed Lambda Calculus}

TypeOperators allows us to define types using infix operator :->.
'infixr :-> 9' sets strongest right assoicativity (matches usual convention that a -> b -> c ~ a -> (b -> c))

Problem: Only want to normalise well typed terms.
Criteria: 
(1) Exclude $\lambda x . y$ - y free variable so not in typing context
(2) Exclude $\lambda x.xx$ - untypable (types are finite)

Problem with standard terms - can't carry type information

\subsection{Typed Term solution - GADTs}

\cite{GADTs}
Explicit type constructor arguments
Language extensions:
DataKinds, TypeOperators, PolyKinds, GADTs.

Example 1: Vec - indexed type advantage since total function

Fails for replicate without work \cite{DependentHaskell}

Advantage over ADTs: type refinement by constructor

Justification of base type \textit{extension work??: string/integer type}
Example 2: IsElem - value as proof
Example 3: Expr - all values well typed by construction

Difference between [] and '[] (kinds vs types) in terms of levels

Big-step evalulator?

Input/Ouput type as pre-condition/post-condition (eg empty context)

\textit{extension work: Introduce context at value level (parameter to function)} 

Restricitions on Haskell
Not full dependent types - need singleton pattern

\section{NbE for the Typed Lambda Calculus}
Investigation: Are GADTs in Haskell powerful enough? Types are erased at runtime so true dependent typing not part of Haskell (programs at type level)

Poissible to erase all type information, NbE on Untyped
Issue: No proof that type preserved 
Solution: Track types as do evaluation - nbe program itself proof that types preserved (subject reduction parallel?)

Started by implementing same as untyped

Main difference in semantics (V := a -> b | Neutral) 
\cite{slides}

problem: Need to strengthen context evaluating body (eval Lam case)
\subsection{Solution: Order Preserving Embeddings (OPEs)}

Following implementation in Agda \cite{AgdaNbe}, agda has full dependent types (type system more powerful) - adapt for haskell, how nicely? 

if a term well typed for one context, also well typed for any longer one

A value of type 'OPE strong weak' can derive weak from strong by dropping elements from context

OPE is a relation on typing contexts

\subsection{Semantic set}

Defintion of V using OPEs - Haskell vs agda

Need to quantify over 'strong' in function - OPE strong weak is guarentee that strong is a stronger context than weak (if quantified at start end up with values where weak stronger than strong) - need rank2 types extension for nested quantification

Helper functions (composition, strengthing relative to OPE) - explain derivations

\subsection{implementing Eval}

Defintion of environment (maps expressions in syntax context ctx to values in semantics with context ctxV)

problem: in app case how to we get identity OPE for semantic context?

But types erased at compile time to make Haskell efficient

How to generate a value at runtime dependent on type erased at compile time

dependent pattern match \cite{SingletonsGuide}

\subsection{Solution: Singleton pattern}

Method of Type to value known as reflection \cite{SingletonsGuide}

Idea: Create value-level tags for types - singleton types correspond type we're interested in, inhabited by only one value for each case

Examples: Reify case analysis, Ty reflection, Context reflection

Explicitly passing as value to pattern match on

Generate implictly using typeclass, use class constraint to imiplictly pass down ability to use contex methods through function calls.
Is it a good idea to have class constraints in the GADTs/Syntax definitions?

Implementation in class vs full reflection - test this for speed?

problem : Inferring Any for ctxV (why?)

solution: scoped type variables - universally quantified variables used in type expressions bind over 'where' clause

(More usefully) can 'unpack' refined GADT types so that can create type definitions using refined types.

Analysis:

Have to specify type when normaling for correct eta-expansion (eta-long form)

Qs:
How does locally nameless work in sematics?
How does ctxV work in Env?

\cite{modalTypes}

\printbibliography

\end{document}